# Updates

## 11 December 2024

??? "Practiced some more SQL on leetcode"
    I continued solving SQL problems to strengthen my understanding of query writing and optimization.

??? "Learnt fundamentals of dbt core for data transformation in the data warehouse"
    Explored dbt Core and its use for managing transformations in modern data warehouses.

??? "Learnt Apache airflow for batch workflow orchestration"
    Gained insights into Apache Airflow's DAG-based approach to orchestrating workflows and pipelines.

??? "Read more about pyspark RDD and Dataframes"
    Understood Spark Context, Spark Architecture, and how Spark integrates with various resource managers for cluster operations.

??? "Setup my development environment again in WSL"
    Configured my dev environment on WSL for a more comfortable Linux-based workflow.

---

## 10 December 2024

??? "Practiced SQL on leetcode"
    Worked on SQL problems to further refine query optimization skills.

??? "Learnt fundamentals of spark using pyspark locally with docker"
    Experimented with PySpark and Docker to get hands-on experience with Spark locally.

??? "Leant databricks"
    Started learning about Databricks but couldnâ€™t fully explore due to the free trial activation pending.

??? "Got myself introduced to Tableau"
    Began exploring Tableau for data visualization and creating dashboards.

??? "Read about data engineering lifecycle"
    Studied the data engineering lifecycle from the book *Fundamentals of Data Engineering* by Joe Reis & Matt Housley.

---

## 9 December 2024

??? "Learning new concepts"
    - Got introduced to:
        - SQL window functions
        - Google BigQuery
        - Databricks
        - Snowflakes

    - Read about:
        - Internals of MySQL: query parser, query optimizers, and executors
        - InnoDB: the default storage engine of MySQL, B/B+ Tree Indexing

??? "Explored GCP"
    Having experience with AWS, I was able to grasp GCP concepts quickly.

??? "Improved git log info extraction"
    - Added CSV and Parquet export format support.
    - Implemented a method to upload exported data (CSV, Parquet) to Google Cloud Storage. (Still needs debugging.)
    - Using Google Cloud Storage as a data lake for storing raw git log data.

---

## 8 December 2024

??? "Worked on a small application"
    Created an application to extract commit logs from a git repository and load the data into an SQL database.

??? "Started a data engineering project"
    - Extracting commit info from git repositories.
    - Processing and analyzing commit data.
    - Visualizing the results on a dashboard.

    This project involves tools and technologies like:
    - SQL, Python, NumPy, Pandas
    - Databricks, Snowflake
    - BI tools like Tableau/Power BI
    - dBT, AWS/GCP (for additional learning)

??? "Planning daily progress automation"
    Using the smaller variant of this project, I plan to:
    - Extract daily commit information.
    - Send automated emails showing my daily progress based on commits as proof of work.

??? "Dived deeper into SQL"
    - Learned about Common Table Expressions (CTEs), PIVOT, UNPIVOT.
    - Understood the differences between Views and CTEs.
